{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQxnfuP7VX1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://l1nna.com/372/Assignment/A2-3/train.csv\n",
        "!wget -q https://l1nna.com/372/Assignment/A2-3/test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WVbJBjQVt4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "\n",
        "xy_train = pd.read_csv('train.csv')\n",
        "x_test  = pd.read_csv('test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPl59bXdWKdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = xy_train.review\n",
        "y = xy_train.rating\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SVC(class_weight='balanced')),\n",
        "])\n",
        "\n",
        "\n",
        "parameters = {\n",
        "    'vect__max_features': [100, 500, 1000, 5000, 10000, 120000],\n",
        "    'vect__analyzer': ['word',],\n",
        "    'vect__ngram_range': ((1, 2),(1, 3)), # unigrams or bigrams or trigrams etc\n",
        "    'tfidf__use_idf': (True, False),\n",
        "#     'tfidf__norm': ('l1', 'l2'),\n",
        "#     'clf__max_iter': (20,),\n",
        "#     'clf__alpha': (0.00001, 0.000001),\n",
        "#     'clf__penalty': ('l2', 'elasticnet'),\n",
        "    # 'clf__max_iter': (10, 50, 80),\n",
        "}\n",
        "\n",
        "scoring = ['f1', 'accuracy']\n",
        "split = int(len(x) * 0.8)\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline, parameters, verbose=3, cv=[(np.arange(0, split), np.arange(split, len(x)))], \n",
        "    refit='f1', n_jobs=20, scoring=scoring, return_train_score=True)\n",
        "grid_search.fit(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcsof-gvWnl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's visualize hyperparameters against performance\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "selected_parameter = 'vect__max_features'\n",
        "results = grid_search.cv_results_\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"GridSearchCV\",\n",
        "          fontsize=16)\n",
        "\n",
        "plt.xlabel(selected_parameter)\n",
        "plt.ylabel(\"Score\")\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_ylim(0.4, 1.1)\n",
        "\n",
        "\n",
        "# Get the regular numpy array from the MaskedArray\n",
        "X_axis = np.array(results['param_'+ selected_parameter].data, dtype=float)\n",
        "\n",
        "scorer = 'f1'\n",
        "color ='b'\n",
        "for sample, style in (('train', '--'), ('test', '-')):\n",
        "    sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
        "    sample_score_mean = [x for _,x in sorted(zip(X_axis,sample_score_mean))]\n",
        "    ax.plot(sorted(X_axis), sample_score_mean, style, color=color,\n",
        "            alpha=1 if sample == 'test' else 0.7,\n",
        "            label=\"%s (%s)\" % (scorer, sample if sample == 'train' else 'validation'))\n",
        "\n",
        "best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
        "best_score = results['mean_test_%s' % scorer][best_index]\n",
        "\n",
        "# Plot a dotted vertical line at the best score for that scorer marked by x\n",
        "ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
        "        linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
        "\n",
        "# Annotate the best score for that scorer\n",
        "ax.annotate(\"%0.2f\" % best_score,\n",
        "            (X_axis[best_index], best_score + 0.005))\n",
        "    \n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItwJEPgIW49m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate submission\n",
        "\n",
        "y_predict = np.squeeze(grid_search.predict(x_test.review))\n",
        "\n",
        "pd.DataFrame(\n",
        "    {'id': x_test.id, 'rating':y_predict}).to_csv('sample_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}