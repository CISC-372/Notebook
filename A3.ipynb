{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQhSr_LqSIg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://l1nna.com/372/Assignment/A2-3/train.csv\n",
        "!wget -q https://l1nna.com/372/Assignment/A2-3/test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaABvQpluwjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "xy_train_df = pd.read_csv('train.csv')\n",
        "x_test_df  = pd.read_csv('test.csv', index_col='id')\n",
        "\n",
        "\n",
        "xy_train_df['length'] = xy_train_df.apply(lambda x: len(x.review), axis=1)\n",
        "xy_train_df = xy_train_df.sort_values('length')\n",
        "xy_train_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHl0DGCyvA7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "vocab_size = 10000\n",
        "max_len = 256\n",
        "\n",
        "xy_train, xy_validation = train_test_split(xy_train_df, test_size=0.2)\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(xy_train.review)\n",
        "\n",
        "# padding is done inside: \n",
        "x_train = tokenizer.texts_to_matrix(xy_train.review, mode='binary')[:, :max_len]\n",
        "y_train = xy_train.rating\n",
        "\n",
        "x_valid = tokenizer.texts_to_matrix(xy_validation.review, mode='binary')[:, :max_len]\n",
        "y_valid = xy_validation.rating\n",
        "\n",
        "x_test = tokenizer.texts_to_matrix(x_test_df.review, mode='binary')[:, :max_len]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EtEv2RivFKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 20))\n",
        "model.add(keras.layers.CuDNNGRU(100))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(clipnorm=4.),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=15,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_valid, y_valid),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_naN0rn3OlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_valid, y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byj-weFZvaaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = np.squeeze(model.predict_classes(x_valid))\n",
        "\n",
        "from sklearn.metrics import  f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(f1_score(y_valid, y_predict, average='micro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FDSaQaxvG0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run on testing set:\n",
        "y_predict = np.squeeze(model.predict_classes(x_test))\n",
        "\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.index,\n",
        "     'rating':y_predict}).to_csv('sample_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}